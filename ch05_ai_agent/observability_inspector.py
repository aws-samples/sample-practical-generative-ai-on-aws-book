#!/usr/bin/env python3
"""
AgentCore Observability ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªãƒ»åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
CloudWatch ãƒ­ã‚°ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®ç¢ºèªæ©Ÿèƒ½
"""

import boto3
import json
import time
from datetime import datetime, timedelta
from botocore.exceptions import ClientError
import argparse

class ObservabilityInspector:
    """Observability ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªãƒ»åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.logs_client = boto3.client('logs')
        self.cloudwatch_client = boto3.client('cloudwatch')
        self.xray_client = boto3.client('xray')
        self.application_signals = boto3.client('application-signals')
        
        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        self.config = self.load_config()
        
    def load_config(self):
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        config = {}
        
        # Observability è¨­å®š
        try:
            with open("observability_config.json", "r") as f:
                config.update(json.load(f))
        except FileNotFoundError:
            print("âš ï¸ observability_config.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # Memory è¨­å®š
        try:
            with open("memory_config.json", "r") as f:
                memory_config = json.load(f)
                config["memory_id"] = memory_config.get("memory_id")
        except FileNotFoundError:
            print("âš ï¸ memory_config.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # Gateway è¨­å®š
        try:
            with open("gateway_config.json", "r") as f:
                gateway_config = json.load(f)
                config["gateway_id"] = gateway_config.get("gateway_id")
        except FileNotFoundError:
            print("âš ï¸ gateway_config.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return config
    
    def get_agent_runtime_logs(self, hours=1, limit=50):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ãƒ­ã‚°ã‚’å–å¾—"""
        
        print(f"ğŸ“ éå»{hours}æ™‚é–“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒ­ã‚°ã‚’å–å¾—ä¸­...")
        
        # ãƒ­ã‚°ç¾¤ã‚’æ¤œç´¢
        log_groups = []
        try:
            response = self.logs_client.describe_log_groups(
                logGroupNamePrefix='/aws/bedrock-agentcore/runtimes/'
            )
            log_groups = [lg['logGroupName'] for lg in response['logGroups']]
            print(f"è¦‹ã¤ã‹ã£ãŸãƒ­ã‚°ç¾¤: {len(log_groups)}å€‹")
            
        except ClientError as e:
            print(f"âŒ ãƒ­ã‚°ç¾¤ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
        
        if not log_groups:
            print("âš ï¸ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ãƒ­ã‚°ç¾¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        # å„ãƒ­ã‚°ç¾¤ã‹ã‚‰ãƒ­ã‚°ã‚’å–å¾—
        all_logs = []
        end_time = int(time.time() * 1000)
        start_time = end_time - (hours * 60 * 60 * 1000)
        
        for log_group in log_groups:
            try:
                response = self.logs_client.filter_log_events(
                    logGroupName=log_group,
                    startTime=start_time,
                    endTime=end_time,
                    limit=limit
                )
                
                events = response.get('events', [])
                for event in events:
                    all_logs.append({
                        'log_group': log_group,
                        'timestamp': datetime.fromtimestamp(event['timestamp'] / 1000),
                        'message': event['message']
                    })
                    
                print(f"  {log_group}: {len(events)}ä»¶ã®ãƒ­ã‚°")
                
            except ClientError as e:
                print(f"âš ï¸ {log_group} ã®ãƒ­ã‚°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ™‚ç³»åˆ—ã§ã‚½ãƒ¼ãƒˆ
        all_logs.sort(key=lambda x: x['timestamp'])
        
        return all_logs
    
    def get_memory_logs(self, hours=1):
        """Memory ãƒªã‚½ãƒ¼ã‚¹ã®ãƒ­ã‚°ã‚’å–å¾—"""
        
        memory_id = self.config.get("memory_id")
        if not memory_id:
            print("âš ï¸ Memory ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        print(f"ğŸ“ Memory {memory_id} ã®éå»{hours}æ™‚é–“ã®ãƒ­ã‚°ã‚’å–å¾—ä¸­...")
        
        log_group_name = f'/aws/vendedlogs/bedrock-agentcore/{memory_id}'
        
        try:
            end_time = int(time.time() * 1000)
            start_time = end_time - (hours * 60 * 60 * 1000)
            
            response = self.logs_client.filter_log_events(
                logGroupName=log_group_name,
                startTime=start_time,
                endTime=end_time
            )
            
            events = response.get('events', [])
            logs = []
            
            for event in events:
                logs.append({
                    'timestamp': datetime.fromtimestamp(event['timestamp'] / 1000),
                    'message': event['message']
                })
            
            print(f"âœ… {len(logs)}ä»¶ã®Memoryãƒ­ã‚°ã‚’å–å¾—ã—ã¾ã—ãŸ")
            return logs
            
        except ClientError as e:
            if "ResourceNotFoundException" in str(e):
                print(f"âš ï¸ Memory ãƒ­ã‚°ç¾¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {log_group_name}")
            else:
                print(f"âŒ Memory ãƒ­ã‚°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def get_cloudwatch_metrics(self, hours=1):
        """CloudWatch ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
        
        print(f"ğŸ“Š éå»{hours}æ™‚é–“ã®CloudWatchãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ä¸­...")
        
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=hours)
        
        metrics_data = {}
        
        # AgentCore ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
        metric_queries = [
            {
                'namespace': 'bedrock-agentcore',
                'metric_name': 'customer_support_requests_total',
                'stat': 'Sum'
            },
            {
                'namespace': 'bedrock-agentcore', 
                'metric_name': 'customer_support_response_time_seconds',
                'stat': 'Average'
            },
            {
                'namespace': 'bedrock-agentcore',
                'metric_name': 'memory_operations_total',
                'stat': 'Sum'
            },
            {
                'namespace': 'bedrock-agentcore',
                'metric_name': 'tool_usage_total',
                'stat': 'Sum'
            }
        ]
        
        for query in metric_queries:
            try:
                response = self.cloudwatch_client.get_metric_statistics(
                    Namespace=query['namespace'],
                    MetricName=query['metric_name'],
                    StartTime=start_time,
                    EndTime=end_time,
                    Period=300,  # 5åˆ†é–“éš”
                    Statistics=[query['stat']]
                )
                
                datapoints = response.get('Datapoints', [])
                if datapoints:
                    # æ™‚ç³»åˆ—ã§ã‚½ãƒ¼ãƒˆ
                    datapoints.sort(key=lambda x: x['Timestamp'])
                    metrics_data[query['metric_name']] = datapoints
                    print(f"  {query['metric_name']}: {len(datapoints)}å€‹ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ")
                else:
                    print(f"  {query['metric_name']}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                    
            except ClientError as e:
                print(f"âš ï¸ {query['metric_name']} ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return metrics_data
    
    def get_xray_traces(self, hours=1):
        """X-Ray ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—"""
        
        print(f"ğŸ” éå»{hours}æ™‚é–“ã®X-Rayãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
        
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=hours)
        
        try:
            # ãƒˆãƒ¬ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼ã‚’å–å¾—
            response = self.xray_client.get_trace_summaries(
                TimeRangeType='TimeRangeByStartTime',
                StartTime=start_time,
                EndTime=end_time,
                FilterExpression='service("bedrock-agentcore")'
            )
            
            trace_summaries = response.get('TraceSummaries', [])
            print(f"âœ… {len(trace_summaries)}å€‹ã®ãƒˆãƒ¬ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸ")
            
            # è©³ç´°ãªãƒˆãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæœ€åˆã®5å€‹ï¼‰
            detailed_traces = []
            for summary in trace_summaries[:5]:
                trace_id = summary['Id']
                
                try:
                    trace_response = self.xray_client.batch_get_traces(
                        TraceIds=[trace_id]
                    )
                    
                    traces = trace_response.get('Traces', [])
                    if traces:
                        detailed_traces.append({
                            'trace_id': trace_id,
                            'duration': summary.get('Duration', 0),
                            'response_time': summary.get('ResponseTime', 0),
                            'segments': len(traces[0].get('Segments', []))
                        })
                        
                except ClientError as e:
                    print(f"âš ï¸ ãƒˆãƒ¬ãƒ¼ã‚¹ {trace_id} ã®è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
            return {
                'summaries': trace_summaries,
                'detailed': detailed_traces
            }
            
        except ClientError as e:
            print(f"âŒ X-Ray ãƒˆãƒ¬ãƒ¼ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'summaries': [], 'detailed': []}
    
    def analyze_performance(self, metrics_data):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
        
        print("\nğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ:")
        print("=" * 50)
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°åˆ†æ
        if 'customer_support_requests_total' in metrics_data:
            requests = metrics_data['customer_support_requests_total']
            total_requests = sum(dp['Sum'] for dp in requests)
            print(f"ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {total_requests}")
            
            if requests:
                avg_requests_per_period = total_requests / len(requests)
                print(f"å¹³å‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°/5åˆ†: {avg_requests_per_period:.2f}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“åˆ†æ
        if 'customer_support_response_time_seconds' in metrics_data:
            response_times = metrics_data['customer_support_response_time_seconds']
            if response_times:
                avg_response_time = sum(dp['Average'] for dp in response_times) / len(response_times)
                max_response_time = max(dp['Average'] for dp in response_times)
                min_response_time = min(dp['Average'] for dp in response_times)
                
                print(f"å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {avg_response_time:.2f}ç§’")
                print(f"æœ€å¤§ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {max_response_time:.2f}ç§’")
                print(f"æœ€å°ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {min_response_time:.2f}ç§’")
        
        # ãƒ„ãƒ¼ãƒ«ä½¿ç”¨åˆ†æ
        if 'tool_usage_total' in metrics_data:
            tool_usage = metrics_data['tool_usage_total']
            total_tool_usage = sum(dp['Sum'] for dp in tool_usage)
            print(f"ç·ãƒ„ãƒ¼ãƒ«ä½¿ç”¨å›æ•°: {total_tool_usage}")
        
        # Memoryæ“ä½œåˆ†æ
        if 'memory_operations_total' in metrics_data:
            memory_ops = metrics_data['memory_operations_total']
            total_memory_ops = sum(dp['Sum'] for dp in memory_ops)
            print(f"ç·Memoryæ“ä½œå›æ•°: {total_memory_ops}")
    
    def generate_report(self, hours=1):
        """åŒ…æ‹¬çš„ãªObservabilityãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        print(f"ğŸ“Š éå»{hours}æ™‚é–“ã®Observabilityãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        print("=" * 60)
        
        # ãƒ‡ãƒ¼ã‚¿åé›†
        agent_logs = self.get_agent_runtime_logs(hours)
        memory_logs = self.get_memory_logs(hours)
        metrics_data = self.get_cloudwatch_metrics(hours)
        traces_data = self.get_xray_traces(hours)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = {
            'timestamp': datetime.utcnow().isoformat(),
            'time_range_hours': hours,
            'summary': {
                'agent_log_entries': len(agent_logs),
                'memory_log_entries': len(memory_logs),
                'metrics_collected': len(metrics_data),
                'traces_found': len(traces_data['summaries'])
            },
            'agent_logs': agent_logs[-10:],  # æœ€æ–°10ä»¶
            'memory_logs': memory_logs[-10:],  # æœ€æ–°10ä»¶
            'metrics': metrics_data,
            'traces': traces_data
        }
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        self.analyze_performance(metrics_data)
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        report_filename = f"observability_report_{int(time.time())}.json"
        with open(report_filename, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nâœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ {report_filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        return report
    
    def show_dashboard_info(self):
        """CloudWatch ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æƒ…å ±ã‚’è¡¨ç¤º"""
        
        print("\nğŸ¯ CloudWatch ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¢ã‚¯ã‚»ã‚¹æƒ…å ±:")
        print("=" * 50)
        
        region = boto3.Session().region_name or 'us-east-1'
        
        print(f"ğŸŒ Generative AI Observability ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰:")
        print(f"   https://console.aws.amazon.com/cloudwatch/home?region={region}#gen-ai-observability")
        
        print(f"\nğŸ“ CloudWatch ãƒ­ã‚°:")
        print(f"   https://console.aws.amazon.com/cloudwatch/home?region={region}#logsV2:log-groups")
        
        print(f"\nğŸ“Š CloudWatch ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        print(f"   https://console.aws.amazon.com/cloudwatch/home?region={region}#metricsV2:")
        
        print(f"\nğŸ” X-Ray ãƒˆãƒ¬ãƒ¼ã‚¹:")
        print(f"   https://console.aws.amazon.com/xray/home?region={region}#/traces")
        
        print(f"\nğŸ” Transaction Search:")
        print(f"   https://console.aws.amazon.com/cloudwatch/home?region={region}#application-signals:services")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    parser = argparse.ArgumentParser(description='AgentCore Observability ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªãƒ»åˆ†æ')
    parser.add_argument('command', choices=['logs', 'metrics', 'traces', 'report', 'dashboard'], 
                       help='å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰')
    parser.add_argument('--hours', type=int, default=1, 
                       help='ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚é–“ç¯„å›²ï¼ˆæ™‚é–“ï¼‰')
    
    args = parser.parse_args()
    
    inspector = ObservabilityInspector()
    
    if args.command == 'logs':
        # ãƒ­ã‚°ç¢ºèª
        agent_logs = inspector.get_agent_runtime_logs(args.hours)
        memory_logs = inspector.get_memory_logs(args.hours)
        
        print(f"\nğŸ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ­ã‚°ï¼ˆæœ€æ–°10ä»¶ï¼‰:")
        for log in agent_logs[-10:]:
            print(f"  {log['timestamp']}: {log['message'][:100]}...")
        
        print(f"\nğŸ“ Memoryãƒ­ã‚°ï¼ˆæœ€æ–°10ä»¶ï¼‰:")
        for log in memory_logs[-10:]:
            print(f"  {log['timestamp']}: {log['message'][:100]}...")
    
    elif args.command == 'metrics':
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
        metrics_data = inspector.get_cloudwatch_metrics(args.hours)
        inspector.analyze_performance(metrics_data)
    
    elif args.command == 'traces':
        # ãƒˆãƒ¬ãƒ¼ã‚¹ç¢ºèª
        traces_data = inspector.get_xray_traces(args.hours)
        
        print(f"\nğŸ” ãƒˆãƒ¬ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼:")
        for trace in traces_data['detailed']:
            print(f"  ID: {trace['trace_id'][:16]}...")
            print(f"    ç¶™ç¶šæ™‚é–“: {trace['duration']:.2f}ç§’")
            print(f"    ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {trace['segments']}")
    
    elif args.command == 'report':
        # åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        inspector.generate_report(args.hours)
    
    elif args.command == 'dashboard':
        # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æƒ…å ±è¡¨ç¤º
        inspector.show_dashboard_info()

if __name__ == "__main__":
    main()